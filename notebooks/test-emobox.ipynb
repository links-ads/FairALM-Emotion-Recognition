{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a537ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = Path.cwd()\n",
    "if cwd.name == \"notebooks\":\n",
    "    os.chdir(cwd.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5886cccb",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bef8bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EmoBox.EmoBox import EmoDataset, EmoEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9117126f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "since there is no official valid data, use random split for train valid split, with a ratio of [80, 20]\n",
      "load in 23800 samples, only 23782 exists in data dir EmoBox/data/\n",
      "load in 7929 samples, only 7923 exists in data dir EmoBox/data/\n",
      "Num. training samples 23782\n",
      "Num. valid samples 0\n",
      "Num. test samples 7923\n",
      "Using label_map {'neutral': 'Neutral', 'angry': 'Angry', 'contempt': 'Contempt', 'disgusted': 'Disgust', 'fear': 'Fear', 'happy': 'Happy', 'sad': 'Sad', 'surprised': 'Surprise'}\n",
      "since there is no official valid data, use random split for train valid split, with a ratio of [80, 20]\n",
      "load in 23800 samples, only 23782 exists in data dir EmoBox/data/\n",
      "load in 7929 samples, only 7923 exists in data dir EmoBox/data/\n",
      "Num. training samples 23782\n",
      "Num. valid samples 0\n",
      "Num. test samples 7923\n",
      "Using label_map {'neutral': 'Neutral', 'angry': 'Angry', 'contempt': 'Contempt', 'disgusted': 'Disgust', 'fear': 'Fear', 'happy': 'Happy', 'sad': 'Sad', 'surprised': 'Surprise'}\n"
     ]
    }
   ],
   "source": [
    "dataset = \"mead\"\n",
    "fold = 1  # different datasets have different number of folds, which can be find in data/\n",
    "user_data_dir = \"./\" # path to EmoBox - FIXED: Changed from \"Emobox\" to \"EmoBox\"\n",
    "meta_data_dir = \"EmoBox/data/\" # path to data folder - FIXED: Changed from \"Emobox\" to \"EmoBox\"\n",
    "\n",
    "\n",
    "train = EmoDataset(dataset, user_data_dir, meta_data_dir, fold=fold, split=\"train\")\n",
    "test = EmoDataset(dataset, user_data_dir, meta_data_dir, fold=fold, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61e3bfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/marquez/FairMLLM-Emotion-Recognition/EmoBox/EmoBox/EmoDataset.py:173: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  wav, sr = librosa.load(wav_path, sr=None, mono=False)\n",
      "/nfs/home/marquez/FairMLLM-Emotion-Recognition/.venv/lib/python3.12/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'key': 'mead-W019-neutral-level-1-020',\n",
       " 'audio': array([ 1.38184987e-07, -1.18045136e-07,  9.90985427e-08, ...,\n",
       "         4.59661795e-04,  7.03288708e-04,  0.00000000e+00],\n",
       "       shape=(74070,), dtype=float32),\n",
       " 'label': 'Neutral',\n",
       " 'gender': 'Female',\n",
       " 'language': 'English'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = test[0]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f2c345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['Neutral', 'Happy', 'Sad', 'Surprise', 'Disgust', 'Angry', 'Fear'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.label_map.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95bb1623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Neutral': 384, 'Happy': 278, 'Angry': 229, 'Sad': 194})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "labels =  [data['label'] for data in test]\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ecf386",
   "metadata": {},
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03cbe8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/dasaro/research/FairMLLM-Emotion-Recognition/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:02<00:00,  1.86it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mllm_emotion_classifier.models import ModelFactory\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = ModelFactory.create(\n",
    "    name=\"qwen2-audio\",\n",
    "    checkpoint=\"Qwen/Qwen2-Audio-7B\",\n",
    "    class_labels=set(train.label_map.values()),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7b459f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test,\n",
    "    batch_size=1,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    "    collate_fn=model.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f599406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# predictions, labels = [], []\n",
    "# i = 0\n",
    "# for inputs, lbl in tqdm(data_loader, total=len(data_loader)):\n",
    "#     inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "#     preds = model.predict(inputs)\n",
    "#     predictions.extend(preds)\n",
    "#     labels.extend(lbl)\n",
    "#     i += 1\n",
    "#     if i == 100: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d32b4",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7045a669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Evaluating Qwen2-Audio-7B on iemocap\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:   0%|                                                                                                                                           | 0/1085 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Inference:   9%|███████████▉                                                                                                                     | 100/1085 [00:22<03:40,  4.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'timestamp': '2025-11-27 09:48:45',\n",
       " 'dataset': 'iemocap',\n",
       " 'model_name': 'Qwen2-Audio-7B',\n",
       " 'fold': None,\n",
       " 'num_samples': 101,\n",
       " 'num_valid_predictions': np.int64(101),\n",
       " 'class_labels': ['Angry', 'Happy', 'Neutral', 'Sad'],\n",
       " 'metrics': {'overall': {'accuracy': {'Angry': 0.8713,\n",
       "    'Happy': 0.901,\n",
       "    'Neutral': 0.7723,\n",
       "    'Sad': 0.901},\n",
       "   'false_positive_rate': {'Angry': 0.0161,\n",
       "    'Happy': 0.0918,\n",
       "    'Neutral': 0.2364,\n",
       "    'Sad': 0.0568},\n",
       "   'false_negative_rate': {'Angry': 0.3077,\n",
       "    'Happy': 0.3333,\n",
       "    'Neutral': 0.2174,\n",
       "    'Sad': 0.3846},\n",
       "   'true_positive_rate': {'Angry': 0.6923,\n",
       "    'Happy': 0.6667,\n",
       "    'Neutral': 0.7826,\n",
       "    'Sad': 0.6154},\n",
       "   'true_negative_rate': {'Angry': 0.9839,\n",
       "    'Happy': 0.9082,\n",
       "    'Neutral': 0.7636,\n",
       "    'Sad': 0.9432},\n",
       "   'positive_predictive_value': {'Angry': 0.9643,\n",
       "    'Happy': 0.1818,\n",
       "    'Neutral': 0.7347,\n",
       "    'Sad': 0.6154},\n",
       "   'negative_predictive_value': {'Angry': 0.8356,\n",
       "    'Happy': 0.9889,\n",
       "    'Neutral': 0.8077,\n",
       "    'Sad': 0.9432},\n",
       "   'f1_score': {'Angry': 0.806,\n",
       "    'Happy': 0.2857,\n",
       "    'Neutral': 0.7579,\n",
       "    'Sad': 0.6154}}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mllm_emotion_classifier.evaluate import Evaluator\n",
    "\n",
    "evaluator = Evaluator()\n",
    "evaluator.evaluate(model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "840f8093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timestamp': '2025-11-27 09:48:45',\n",
       " 'dataset': 'iemocap',\n",
       " 'model_name': 'Qwen2-Audio-7B',\n",
       " 'fold': None,\n",
       " 'num_samples': 101,\n",
       " 'num_valid_predictions': np.int64(101),\n",
       " 'class_labels': ['Angry', 'Happy', 'Neutral', 'Sad'],\n",
       " 'metrics': {'overall': {'accuracy': {'Angry': 0.8713,\n",
       "    'Happy': 0.901,\n",
       "    'Neutral': 0.7723,\n",
       "    'Sad': 0.901},\n",
       "   'false_positive_rate': {'Angry': 0.0161,\n",
       "    'Happy': 0.0918,\n",
       "    'Neutral': 0.2364,\n",
       "    'Sad': 0.0568},\n",
       "   'false_negative_rate': {'Angry': 0.3077,\n",
       "    'Happy': 0.3333,\n",
       "    'Neutral': 0.2174,\n",
       "    'Sad': 0.3846},\n",
       "   'true_positive_rate': {'Angry': 0.6923,\n",
       "    'Happy': 0.6667,\n",
       "    'Neutral': 0.7826,\n",
       "    'Sad': 0.6154},\n",
       "   'true_negative_rate': {'Angry': 0.9839,\n",
       "    'Happy': 0.9082,\n",
       "    'Neutral': 0.7636,\n",
       "    'Sad': 0.9432},\n",
       "   'positive_predictive_value': {'Angry': 0.9643,\n",
       "    'Happy': 0.1818,\n",
       "    'Neutral': 0.7347,\n",
       "    'Sad': 0.6154},\n",
       "   'negative_predictive_value': {'Angry': 0.8356,\n",
       "    'Happy': 0.9889,\n",
       "    'Neutral': 0.8077,\n",
       "    'Sad': 0.9432},\n",
       "   'f1_score': {'Angry': 0.806,\n",
       "    'Happy': 0.2857,\n",
       "    'Neutral': 0.7579,\n",
       "    'Sad': 0.6154}}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
