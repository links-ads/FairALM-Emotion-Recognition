{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b17bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# %pip install mistral-common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df6d2c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = Path.cwd()\n",
    "if cwd.name == \"notebooks\":\n",
    "    os.chdir(cwd.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b81dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525b731c1e0d40c3a411c4ad8f5c1ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74eee2e568f74b7d9f875ceb67c59ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tekken.json:   0%|          | 0.00/14.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9743d61d7d16412d829327c30bc16b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d762d44baf4537a17c7da36245d175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d912eb7f41b54c39a4d88751c101b6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565eae9a057e490c9326990c6b675c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.38G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0bac360090a436699771c7e879703d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a96c769b0941088fbe65b999001e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c1e83f831b43f3aab7df3b0388a3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/108 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import VoxtralForConditionalGeneration, AutoProcessor\n",
    "import torch\n",
    "\n",
    "device = \"cuda\"\n",
    "repo_id = \"mistralai/Voxtral-Mini-3B-2507\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(repo_id)\n",
    "model = VoxtralForConditionalGeneration.from_pretrained(\n",
    "    repo_id,\n",
    "    dtype=torch.bfloat16,\n",
    "    device_map=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "806b1723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "since there is no official valid data, use random split for train valid split, with a ratio of [80, 20]\n",
      "load in 28000 samples, only 28000 exists in data dir EmoBox/data/\n",
      "load in 7000 samples, only 7000 exists in data dir EmoBox/data/\n",
      "Num. training samples 28000\n",
      "Num. valid samples 0\n",
      "Num. test samples 7000\n",
      "Using label_map {'Neutral': 'Neutral', 'Angry': 'Angry', 'Happy': 'Happy', 'Sad': 'Sad', 'Surprise': 'Surprise'}\n",
      "since there is no official valid data, use random split for train valid split, with a ratio of [80, 20]\n",
      "load in 28000 samples, only 28000 exists in data dir EmoBox/data/\n",
      "load in 7000 samples, only 7000 exists in data dir EmoBox/data/\n",
      "Num. training samples 28000\n",
      "Num. valid samples 0\n",
      "Num. test samples 7000\n",
      "Using label_map {'Neutral': 'Neutral', 'Angry': 'Angry', 'Happy': 'Happy', 'Sad': 'Sad', 'Surprise': 'Surprise'}\n"
     ]
    }
   ],
   "source": [
    "from EmoBox.EmoBox import EmoDataset, EmoEval\n",
    "\n",
    "dataset = \"esd\"\n",
    "fold = 1  # different datasets have different number of folds, which can be find in data/\n",
    "user_data_dir = \"./\" # path to EmoBox - FIXED: Changed from \"Emobox\" to \"EmoBox\"\n",
    "meta_data_dir = \"EmoBox/data/\" # path to data folder - FIXED: Changed from \"Emobox\" to \"EmoBox\"\n",
    "label2idx = {'hap':0, 'sad':1, 'ang':2, 'neu':3} # you may need to define a label to index mapping for your own training, see `data/iemocap/label_map.json`\n",
    "\n",
    "train = EmoDataset(dataset, user_data_dir, meta_data_dir, fold=fold, split=\"train\")\n",
    "test = EmoDataset(dataset, user_data_dir, meta_data_dir, fold=fold, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a71b165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neutral']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"audio\",\n",
    "                \"path\": str(test.data_list[0]['wav']),\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"Choose one of the emotions that this audio is portraying between ['Neutral', 'Happy', 'Angry', 'Sad']:\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "inputs = processor.apply_chat_template(conversation)\n",
    "inputs = inputs.to(device, dtype=torch.bfloat16)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=30)\n",
    "processor.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
